{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gbUiFCWmFIee"
      },
      "outputs": [],
      "source": [
        "import os, glob\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Conv2D\n",
        "from keras.models import Model\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense, Input, BatchNormalization, Concatenate, GlobalAveragePooling2D\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import img_to_array, load_img, array_to_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GmXRnBZiCW_b"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QwfKY_FuFIeg"
      },
      "outputs": [],
      "source": [
        "# seed 고정\n",
        "seed = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wx5EI4W0CYKv"
      },
      "outputs": [],
      "source": [
        "folder_list = os.listdir('./faces/여자')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VEk1E7rbCZ1i"
      },
      "outputs": [],
      "source": [
        "# # 이미지 증강용\n",
        "# def IDG(fname): #파일이름을 변수로 받는 ImageDataGenerator함수\n",
        "#    ImageDG = ImageDataGenerator(\n",
        "#        rescale = 1. / 255, # 이미지 value 정규화화\n",
        "#        rotation_range = 90, # 무작위 회전의 각도 범위\n",
        "#        brightness_range = [0.3,1.0], # 밝기 범위위\n",
        "#        fill_mode='nearest' # 인풋 경계의 바깥공간 채우는 방식\n",
        "#        )\n",
        "   \n",
        "#    img = tf.keras.preprocessing.image.load_img(fname) # 이미지파일로 변환\n",
        "#    x = img_to_array(img)\n",
        "#    x = x.reshape((1,) + x.shape)\n",
        "#    i=1\n",
        "#    save = fname.split('/')[0] + \"/\" + fname.split('/')[1] + \"/\" + fname.split('/')[2] + \"/\" + fname.split('/')[3]\n",
        "#    # 생성된 파일 저장경로\n",
        "#    for batch in ImageDG.flow(x, batch_size=1, save_to_dir = save, save_prefix='new'+fname.split('/')[3], save_format='png'):\n",
        "#        i+=1\n",
        "#        if i>=10: # 새로 생성되는 데이터 개수 정해주기\n",
        "#            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IOh1C9lQCc6U"
      },
      "outputs": [],
      "source": [
        "# # 이미지 증강용\n",
        "# folder_list = os.listdir('./faces/여자')\n",
        "# fname =  './faces/여자/'\n",
        "# for f in folder_list:\n",
        "#     fname =  './faces/여자/' + f +\"/\"\n",
        "#     file_list = os.listdir(fname)\n",
        "#     for i in file_list:\n",
        "#         filename = fname + i\n",
        "#         IDG(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "e-0hfaVwFIeh"
      },
      "outputs": [],
      "source": [
        "# 분류 대상 카테고리 선택하기 \n",
        "faces_dir = './faces/여자'\n",
        "woman_categories = [\n",
        "    '가을','단아','리라','성아','순정','유리','주경','하민'\n",
        "]\n",
        "nb_classes = len(woman_categories)\n",
        "# 이미지 크기 지정 \n",
        "image_w = 256\n",
        "image_h = 256\n",
        "pixels = image_w * image_h * 3\n",
        "# 이미지 데이터 읽어 들이기 \n",
        "X = []\n",
        "Y = []\n",
        "for idx, cat in enumerate(woman_categories):\n",
        "    # 레이블 지정 \n",
        "    label = [0 for i in range(nb_classes)]\n",
        "    label[idx] = 1\n",
        "    # 이미지 \n",
        "    image_dir = faces_dir + \"/\" + cat\n",
        "    files = glob.glob(image_dir+\"/*.png\")\n",
        "    for i, f in enumerate(files):\n",
        "        img = Image.open(f) \n",
        "        img = img.convert(\"RGB\")\n",
        "        img = img.resize((image_w, image_h))\n",
        "        data = np.asarray(img)      # numpy 배열로 변환\n",
        "        X.append(data)\n",
        "        Y.append(label)\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "302fGcsRCtBU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5064, 256, 256, 3)\n",
            "(5064, 8)\n"
          ]
        }
      ],
      "source": [
        "print(X.shape)\n",
        "print(Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X_std = X/255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "k_SuSxKpIWFr"
      },
      "outputs": [],
      "source": [
        "resnet = ResNet50(weights='imagenet', include_top=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "b5A3_m1TIWXL"
      },
      "outputs": [],
      "source": [
        "for layer in resnet.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "cX95asFPIXGo"
      },
      "outputs": [],
      "source": [
        "inputs = Input(shape=(256,256,3))\n",
        "res = resnet(inputs)\n",
        "gap = GlobalAveragePooling2D()(res)\n",
        "dense = Dense(128, activation='relu')(gap)\n",
        "outputs = Dense(nb_classes, activation='softmax')(dense)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hVOWL3LPFIei"
      },
      "outputs": [],
      "source": [
        "model = Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2VUjBGbbFIei",
        "outputId": "18c06ed4-fddf-4825-cf84-cfc8f10b4a8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
            "                                                                 \n",
            " resnet50 (Functional)       (None, None, None, 2048)  23587712  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 2048)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               262272    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 1032      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,851,016\n",
            "Trainable params: 263,304\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# 모델 확인\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3UeEvH1PFIei"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Xo6wTDMFFIej"
      },
      "outputs": [],
      "source": [
        "# 학습 전용 데이터와 테스트 전용 데이터 구분 \n",
        "X_train, X_test, y_train, y_test = \\\n",
        "    train_test_split(X_std, Y, random_state=seed, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Fr7Bat16FIej",
        "outputId": "c0388271-81f8-4734-e34c-e4344a0892b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    870\n",
            "1    143\n",
            "Name: 0, dtype: int64\n",
            "0    883\n",
            "1    130\n",
            "Name: 1, dtype: int64\n",
            "0    880\n",
            "1    133\n",
            "Name: 2, dtype: int64\n",
            "0    898\n",
            "1    115\n",
            "Name: 3, dtype: int64\n",
            "0    896\n",
            "1    117\n",
            "Name: 4, dtype: int64\n",
            "0    898\n",
            "1    115\n",
            "Name: 5, dtype: int64\n",
            "0    872\n",
            "1    141\n",
            "Name: 6, dtype: int64\n",
            "0    894\n",
            "1    119\n",
            "Name: 7, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "for i in range(len(pd.DataFrame(y_test).columns)):\n",
        "    print(pd.DataFrame(y_test)[i].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Zj3_b054FIej"
      },
      "outputs": [],
      "source": [
        "# checkpoint_filepath = \"WFMbest.hdf5\"\n",
        "\n",
        "# early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=1)\n",
        "\n",
        "# save_best = tf.keras.callbacks.ModelCheckpoint(\n",
        "#     filepath=checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True,\n",
        "#     save_weights_only=True, mode='auto', save_freq='epoch', options=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "gjG2eQJdFIej",
        "outputId": "b7353bf0-68e8-4307-bf57-491827d9c7a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "127/127 [==============================] - 351s 2s/step - loss: 1.7056 - accuracy: 0.3565 - val_loss: 1.4410 - val_accuracy: 0.3988\n",
            "Epoch 2/10\n",
            "127/127 [==============================] - 321s 3s/step - loss: 1.3098 - accuracy: 0.5315 - val_loss: 1.1206 - val_accuracy: 0.6377\n",
            "Epoch 3/10\n",
            "127/127 [==============================] - 321s 3s/step - loss: 1.1043 - accuracy: 0.6159 - val_loss: 0.9822 - val_accuracy: 0.6436\n",
            "Epoch 4/10\n",
            "127/127 [==============================] - 325s 3s/step - loss: 0.9713 - accuracy: 0.6579 - val_loss: 0.8137 - val_accuracy: 0.7404\n",
            "Epoch 5/10\n",
            "127/127 [==============================] - 339s 3s/step - loss: 0.8735 - accuracy: 0.6890 - val_loss: 0.7336 - val_accuracy: 0.7631\n",
            "Epoch 6/10\n",
            "127/127 [==============================] - 340s 3s/step - loss: 0.7788 - accuracy: 0.7341 - val_loss: 0.7162 - val_accuracy: 0.7315\n",
            "Epoch 7/10\n",
            "127/127 [==============================] - 321s 3s/step - loss: 0.7315 - accuracy: 0.7448 - val_loss: 0.6457 - val_accuracy: 0.7690\n",
            "Epoch 8/10\n",
            "127/127 [==============================] - 318s 3s/step - loss: 0.6794 - accuracy: 0.7662 - val_loss: 0.5961 - val_accuracy: 0.7641\n",
            "Epoch 9/10\n",
            "127/127 [==============================] - 333s 3s/step - loss: 0.6308 - accuracy: 0.7778 - val_loss: 0.5183 - val_accuracy: 0.8322\n",
            "Epoch 10/10\n",
            "127/127 [==============================] - 329s 3s/step - loss: 0.5851 - accuracy: 0.7956 - val_loss: 0.4929 - val_accuracy: 0.8539\n"
          ]
        }
      ],
      "source": [
        "\n",
        "hdf5_file = \"WFMbest.hdf5\"\n",
        "if os.path.exists(hdf5_file):\n",
        "    # 기존에 학습된 모델 불러오기기\n",
        "    model.load_weights(hdf5_file)\n",
        "else:\n",
        "    # 학습한 모델이 없으면 파일로 저장\n",
        "    model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))\n",
        "    model.save_weights(hdf5_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "6c26f6e898609fbfc55f344a153b12e2e0bbde9c2ce650535ffefcc33c127b1e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
